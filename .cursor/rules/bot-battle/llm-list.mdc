---
description: 
globs: 
alwaysApply: false
---

[
    {
    "costType": "userKeyRequired",
    "capabilities": ["text", "image", "code", "json", "tool_use", "long_context", "reasoning"],
    "description": "OpenAI's smartest model for complex tasks, with major gains in coding and instruction following. Features a 1M token context window. [2, 3]"
  },
  {
    "id": "gpt-4.1-mini",
    "displayName": "GPT-4.1 mini",
    "contextWindow": 1000000,
    "cost": {
      "inputPerMillionTokens": 0.40,
      "outputPerMillionTokens": 1.60,
      "currency": "USD",
      "notes": "Cached input: $0.10 / 1M tokens. Fine-tuning: Training $5.00/1M, Input $0.80/1M, Output $3.20/1M. Knowledge cutoff: June 2024. [1, 2]"
    },
    "costType": "userKeyRequired",
    "capabilities": ["text", "image", "code", "json", "tool_use", "long_context"],
    "description": "Affordable OpenAI model balancing speed and intelligence with a 1M token context window. [1, 2, 3]"
  },
  {
    "id": "gpt-4.1-nano",
    "displayName": "GPT-4.1 nano",
    "contextWindow": 1000000,
    "cost": {
      "inputPerMillionTokens": 0.10,
      "outputPerMillionTokens": 0.40,
      "currency": "USD",
      "notes": "Cached input: $0.025 / 1M tokens. Fine-tuning: Training $1.50/1M, Input $0.20/1M, Output $0.80/1M. Knowledge cutoff: June 2024. [1, 2]"
    },
    "costType": "userKeyRequired",
    "capabilities": ["text", "image", "code", "json", "tool_use", "long_context"],
    "description": "Fastest, most cost-effective OpenAI model for low-latency tasks with a 1M token context window. [1, 2, 3]"
  },
  {
    "id": "gpt-4o",
    "displayName": "GPT-4o",
    "contextWindow": 128000,
    "cost": {
      "inputPerMillionTokens": 5.00,
      "outputPerMillionTokens": 20.00,
      "currency": "USD",
      "notes": "Text pricing. Cached input (Text): $2.50/1M. Audio input: $40.00/1M, Audio output: $80.00/1M. Fine-tuning (Text): Training $25.00/1M, Input $3.75/1M, Output $15.00/1M. Knowledge cutoff: Oct 2023. [1, 4, 5]"
    },
    "costType": "userKeyRequired",
    "capabilities": ["text", "image", "audio_input", "audio_output", "code", "json", "tool_use", "multilingual"],
    "description": "OpenAI's flagship multimodal model, natively processing text, audio, and image inputs and outputs. Rapid response times. [4, 6]"
  },
  {
    "id": "gpt-4o-mini",
    "displayName": "GPT-4o mini",
    "contextWindow": 128000,
    "cost": {
      "inputPerMillionTokens": 0.60,
      "outputPerMillionTokens": 2.40,
      "currency": "USD",
      "notes": "Text pricing. Cached input (Text): $0.30/1M. Audio input: $10.00/1M, Audio output: $20.00/1M. Fine-tuning available. Knowledge cutoff: July 2024 (Azure). [1, 4, 7]"
    },
    "costType": "userKeyRequired",
    "capabilities": ["text", "image", "audio_input", "audio_output", "code", "json", "tool_use", "multilingual"],
    "description": "A smaller, faster, and more cost-effective version of GPT-4o, supporting multimodal inputs and outputs. [4, 8]"
  },
  {
    "id": "o3",
    "displayName": "OpenAI o3",
    "contextWindow": 200000,
    "cost": {
      "inputPerMillionTokens": 10.00,
      "outputPerMillionTokens": 40.00,
      "currency": "USD",
      "notes": "Cached input: $2.50 / 1M tokens. Max output tokens: 100,000. Supports reasoning effort settings. [1, 9, 10]"
    },
    "costType": "userKeyRequired",
    "capabilities": ["text", "image", "code", "json", "tool_use", "reasoning", "long_context"],
    "description": "OpenAI's most powerful reasoning model with leading performance on coding, math, science, and vision. Ideal for complex, multi-step problems. [3, 9]"
  },
  {
    "id": "o4-mini",
    "displayName": "OpenAI o4-mini",
    "contextWindow": 200000,
    "cost": {
      "inputPerMillionTokens": 1.10,
      "outputPerMillionTokens": 4.40,
      "currency": "USD",
      "notes": "Cached input: $0.275 / 1M tokens. Reinforcement fine-tuning: Training $100.00/hour, Input $4.00/1M, Output $16.00/1M. Max output tokens: 100,000. [1, 9]"
    },
    "costType": "userKeyRequired",
    "capabilities": ["text", "image", "code", "json", "tool_use", "reasoning", "long_context"],
    "description": "A faster, cost-efficient reasoning model from OpenAI, delivering strong performance on math, coding, and vision. Optimized for high-throughput. [3, 9]"
  },
  {
    "id": "gemini-1.5-pro-latest",
    "displayName": "Gemini 1.5 Pro",
    "contextWindow": 2000000,
    "cost": {
      "inputPerMillionTokens": 1.25,
      "outputPerMillionTokens": 5.00,
      "currency": "USD",
      "notes": "Pricing for prompts <=128K tokens. For prompts >128K: $2.50/1M input, $10.00/1M output. Context caching and Grounding with Google Search available. [11]"
    },
    "costType": "userKeyRequired",
    "capabilities": ["text", "image", "audio", "video", "code", "json", "tool_use", "multilingual", "grounding", "long_context", "reasoning"],
    "description": "Google's highest intelligence Gemini 1.5 series model, with a breakthrough 2 million token context window. Excels at complex coding and reasoning. [11, 12]"
  },
  {
    "id": "gemini-1.5-flash-latest",
    "displayName": "Gemini 1.5 Flash",
    "contextWindow": 1048576,
    "cost": {
      "inputPerMillionTokens": 0.075,
      "outputPerMillionTokens": 0.30,
      "currency": "USD",
      "notes": "Pricing for prompts <=128K tokens. For prompts >128K: $0.15/1M input, $0.60/1M output. Context caching and Grounding with Google Search available. Optimized for speed and cost. [11]"
    },
    "costType": "userKeyRequired",
    "capabilities": ["text", "image", "audio", "video", "code", "json", "tool_use", "multilingual", "grounding", "long_context"],
    "description": "Fast and efficient multimodal model from Google, optimized for diverse, repetitive tasks with a 1 million token context window. [11]"
  },
  {
    "id": "gemini-2.5-pro-preview-05-06",
    "displayName": "Gemini 2.5 Pro Preview",
    "contextWindow": 1048576,
    "cost": {
      "inputPerMillionTokens": 1.25,
      "outputPerMillionTokens": 10.00,
      "currency": "USD",
      "notes": "Pricing for prompts <=200K tokens. For prompts >200K: $2.50/1M input, $15.00/1M output (output includes thinking tokens). Context caching and Grounding with Google Search available. Knowledge cutoff: Jan 2025. [11, 13]"
    },
    "costType": "userKeyRequired",
    "capabilities": ["text", "image", "audio", "video", "code", "json", "tool_use", "multilingual", "grounding", "long_context", "thinking_model", "reasoning"],
    "description": "Google's state-of-the-art thinking model, capable of reasoning over complex problems in code, math, STEM, and analyzing large datasets with long context. [13]"
  },
  {
    "id": "gemini-2.5-flash-preview-04-17",
    "displayName": "Gemini 2.5 Flash Preview",
    "contextWindow": 1048576,
    "cost": {
      "inputPerMillionTokens": 0.15,
      "outputPerMillionTokens": 0.60,
      "currency": "USD",
      "notes": "Pricing for text/image/video input and Non-thinking output. Audio input: $1.00/1M. Thinking output: $3.50/1M. Context caching and Grounding with Google Search available. [11]"
    },
    "costType": "userKeyRequired",
    "capabilities": ["text", "image", "audio", "video", "code", "json", "tool_use", "multilingual", "grounding", "long_context", "thinking_model"],
    "description": "Google's best model for price-performance, offering well-rounded capabilities. Model thinks as needed or with a configured budget. Best for low latency, high volume tasks that require thinking. [13]"
  },
  {
    "id": "gemini-2.0-flash",
    "displayName": "Gemini 2.0 Flash",
    "contextWindow": 1048576,
    "cost": {
      "inputPerMillionTokens": 0.10,
      "outputPerMillionTokens": 0.40,
      "currency": "USD",
      "notes": "Pricing for text/image/video input. Audio input: $0.70/1M. Image generation: $0.039/image. Context caching, Grounding with Google Search, and Live API available. [11]"
    },
    "costType": "userKeyRequired",
    "capabilities": ["text", "image", "audio", "video", "code", "json", "tool_use", "multilingual", "grounding", "image_generation", "live_api", "long_context"],
    "description": "A versatile and cost-effective multimodal model from Google, supporting image generation and live API interactions. [11, 12]"
  },
  {
    "id": "gemini-1.5-flash-8b",
    "displayName": "Gemini 1.5 Flash-8B",
    "contextWindow": 1048576,
    "cost": {
      "inputPerMillionTokens": 0.0375,
      "outputPerMillionTokens": 0.15,
      "currency": "USD",
      "notes": "Pricing for prompts <=128K tokens. For prompts >128K: $0.075/1M input, $0.30/1M output. Context caching and Grounding with Google Search available. [11]"
    },
    "costType": "userKeyRequired",
    "capabilities": ["text", "image", "audio", "video", "code", "json", "tool_use", "multilingual", "grounding", "long_context"],
    "description": "A smaller, highly cost-effective version of Gemini 1.5 Flash, suitable for high-volume, lower complexity tasks with a large context window. [11, 14]"
  },
  {
    "id": "claude-3-7-sonnet-20250219",
    "displayName": "Claude 3.7 Sonnet",
    "contextWindow": 200000,
    "cost": {
      "inputPerMillionTokens": 3.00,
      "outputPerMillionTokens": 15.00,
      "currency": "USD",
      "notes": "Cache Writes: $3.75/MTok, Cache Hits: $0.30/MTok. Training data cut-off: Nov 2024. [15, 16]"
    },
    "costType": "userKeyRequired",
    "capabilities": ["text", "image", "code", "json", "tool_use", "multilingual", "extended_thinking", "reasoning", "long_context"],
    "description": "Anthropic's most intelligent model with visible step-by-step reasoning and toggleable extended thinking. Top-tier benchmark performance. [15, 16]"
  },
  {
    "id": "claude-3-5-sonnet-20241022",
    "displayName": "Claude 3.5 Sonnet",
    "contextWindow": 200000,
    "cost": {
      "inputPerMillionTokens": 3.00,
      "outputPerMillionTokens": 15.00,
      "currency": "USD",
      "notes": "Cache Writes: $3.75/MTok, Cache Hits: $0.30/MTok. Training data cut-off: Apr 2024. [15, 16]"
    },
    "costType": "userKeyRequired",
    "capabilities": ["text", "image", "code", "json", "tool_use", "multilingual", "long_context"],
    "description": "Anthropic's hard-working model offering a strong balance of intelligence and speed for enterprise workloads. [15, 17]"
  },
  {
    "id": "claude-3-5-haiku-20241022",
    "displayName": "Claude 3.5 Haiku",
    "contextWindow": 200000,
    "cost": {
      "inputPerMillionTokens": 0.80,
      "outputPerMillionTokens": 4.00,
      "currency": "USD",
      "notes": "Cache Writes: $1.00/MTok, Cache Hits: $0.08/MTok. Training data cut-off: July 2024. [15, 16]"
    },
    "costType": "userKeyRequired",
    "capabilities": ["text", "image", "code", "json", "tool_use", "multilingual", "long_context"],
    "description": "Anthropic's fastest and most cost-effective model in the Claude 3.5 family, offering intelligence at blazing speeds. [15, 16]"
  },
  {
    "id": "claude-3-opus-20240229",
    "displayName": "Claude 3 Opus",
    "contextWindow": 200000,
    "cost": {
      "inputPerMillionTokens": 15.00,
      "outputPerMillionTokens": 75.00,
      "currency": "USD",
      "notes": "Cache Writes: $18.75/MTok, Cache Hits: $1.50/MTok. Training data cut-off: Aug 2023. [15, 16]"
    },
    "costType": "userKeyRequired",
    "capabilities": ["text", "image", "code", "json", "tool_use", "multilingual", "reasoning", "long_context"],
    "description": "Anthropic's most powerful Claude 3 model for complex analysis, longer tasks, and higher-order math and coding. [15, 17]"
  },
  {
    "id": "claude-3-haiku-20240307",
    "displayName": "Claude 3 Haiku",
    "contextWindow": 200000,
    "cost": {
      "inputPerMillionTokens": 0.25,
      "outputPerMillionTokens": 1.25,
      "currency": "USD",
      "notes": "Cache Writes: $0.30/MTok, Cache Hits: $0.03/MTok. Training data cut-off: Aug 2023. [15, 16]"
    },
    "costType": "userKeyRequired",
    "capabilities": ["text", "image", "code", "json", "tool_use", "multilingual", "long_context"],
    "description": "Anthropic's fastest and most compact Claude 3 model for near-instant responsiveness and quick, accurate targeted performance. [15, 17]"
  },
  {
    "id": "mistral-large-latest",
    "displayName": "Mistral Large",
    "contextWindow": 128000,
    "cost": {
      "inputPerMillionTokens": 2.00,
      "outputPerMillionTokens": 6.00,
      "currency": "USD",
      "notes": "EUR pricing also available. Top-tier reasoning for high-complexity tasks. `mistral-large-latest` points to `mistral-large-2411` (Knowledge cutoff Nov 2024). [18, 19]"
    },
    "costType": "userKeyRequired",
    "capabilities": ["text", "code", "json", "tool_use", "multilingual", "reasoning", "long_context"],
    "description": "Mistral's top-tier reasoning model for high-complexity tasks and sophisticated problems. Strong multilingual and coding support. [18, 20, 21]"
  },
  {
    "id": "mistral-medium-latest",
    "displayName": "Mistral Medium 3",
    "contextWindow": 128000,
    "cost": {
      "inputPerMillionTokens": 0.40,
      "outputPerMillionTokens": 2.00,
      "currency": "USD",
      "notes": "EUR pricing also available. `mistral-medium-latest` points to `mistral-medium-2505` (Knowledge cutoff May 2025). [18, 19]"
    },
    "costType": "userKeyRequired",
    "capabilities": ["text", "image", "code", "json", "tool_use", "multilingual", "long_context"],
    "description": "State-of-the-art Mistral model balancing frontier-class multimodal performance with size and pricing. Cost-efficient for enterprise. [18, 19, 21]"
  },
  {
    "id": "mistral-small-latest",
    "displayName": "Mistral Small 3.1",
    "contextWindow": 128000,
    "cost": {
      "inputPerMillionTokens": 0.10,
      "outputPerMillionTokens": 0.30,
      "currency": "USD",
      "notes": "EUR pricing also available. Apache 2.0 license. `mistral-small-latest` points to `mistral-small-2503` (Knowledge cutoff March 2025). [18, 19]"
    },
    "costType": "userKeyRequired",
    "capabilities": ["text", "image", "code", "json", "tool_use", "multilingual", "long_context"],
    "description": "A multimodal leader in the small models category from Mistral. SOTA, multilingual, and Apache 2.0 licensed. [18, 19, 21]"
  },
  {
    "id": "pixtral-large-latest",
    "displayName": "Pixtral Large",
    "contextWindow": 128000,
    "cost": {
      "inputPerMillionTokens": 2.00,
      "outputPerMillionTokens": 6.00,
      "currency": "USD",
      "notes": "EUR pricing also available. `pixtral-large-latest` points to `pixtral-large-2411` (Knowledge cutoff Nov 2024). [18, 19]"
    },
    "costType": "userKeyRequired",
    "capabilities": ["text", "image", "code", "json", "tool_use", "multilingual", "reasoning", "long_context"],
    "description": "Mistral's vision-capable large model with frontier reasoning capabilities. Multimodal and multilingual. [18, 19, 21]"
  },
  {
    "id": "mistral-saba-latest",
    "displayName": "Mistral Saba",
    "contextWindow": 32000,
    "cost": {
      "inputPerMillionTokens": 0.20,
      "outputPerMillionTokens": 0.60,
      "currency": "USD",
      "notes": "EUR pricing also available. `mistral-saba-latest` points to `mistral-saba-2502` (Knowledge cutoff Feb 2025). [18, 19]"
    },
    "costType": "userKeyRequired",
    "capabilities": ["text", "json", "tool_use", "multilingual"],
    "description": "A powerful and efficient Mistral model custom-trained for languages from the Middle East and South Asia. [18, 19, 21]"
  },
  {
    "id": "ministral-8b-latest",
    "displayName": "Ministral 8B",
    "contextWindow": 128000,
    "cost": {
      "inputPerMillionTokens": 0.10,
      "outputPerMillionTokens": 0.10,
      "currency": "USD",
      "notes": "EUR pricing also available for `Ministral 8B 24.10`. `ministral-8b-latest` points to `ministral-8b-2410` (Knowledge cutoff Oct 2024). [18, 19]"
    },
    "costType": "userKeyRequired",
    "capabilities": ["text", "code", "json", "tool_use", "multilingual", "long_context"],
    "description": "Powerful Mistral edge model with extremely high performance/price ratio, suitable for on-device use cases. [18, 19, 21]"
  },
  {
    "id": "ministral-3b-latest",
    "displayName": "Ministral 3B",
    "contextWindow": 128000,
    "cost": {
      "inputPerMillionTokens": 0.04,
      "outputPerMillionTokens": 0.04,
      "currency": "USD",
      "notes": "EUR pricing also available for `Ministral 3B 24.10`. `ministral-3b-latest` points to `ministral-3b-2410` (Knowledge cutoff Oct 2024). [18, 19]"
    },
    "costType": "userKeyRequired",
    "capabilities": ["text", "code", "json", "tool_use", "multilingual", "long_context"],
    "description": "Mistral's most efficient edge model, offering unprecedented performance for resource-constrained environments. [18, 19, 21]"
  },
  {
    "id": "mistral-embed",
    "displayName": "Mistral Embed",
    "contextWindow": 8000,
    "cost": {
      "inputPerMillionTokens": 0.10,
      "outputPerMillionTokens": 0.0,
      "currency": "USD",
      "notes": "EUR pricing also available. Output is a vector representation. Knowledge cutoff Dec 2023. [18, 19]"
    },
    "costType": "userKeyRequired",
    "capabilities": ["text", "embeddings", "multilingual"],
    "description": "Mistral's state-of-the-art semantic model for extracting representations of text extracts, useful for RAG. [18, 19, 21]"
  },
  {
    "id": "mistral-ocr-latest",
    "displayName": "Mistral OCR",
    "contextWindow": 0,
    "cost": {
      "inputPerMillionTokens": 0.50,
      "outputPerMillionTokens": 0.0,
      "currency": "USD",
      "notes": "Pricing is $1.00 per 1000 pages (approx. $0.50/1M tokens if 1 page ~2k tokens). Output is extracted text. `mistral-ocr-latest` points to version from March 2025. [18, 19]"
    },
    "costType": "userKeyRequired",
    "capabilities": ["image", "text_extraction"],
    "description": "Mistral's OCR service that enables users to extract interleaved text and images from documents. [18, 19, 21]"
  },
  {
    "id": "command-r-plus",
    "displayName": "Command R+",
    "contextWindow": 128000,
    "cost": {
      "inputPerMillionTokens": 3.00,
      "outputPerMillionTokens": 9.00,
      "currency": "USD",
      "notes": "Optimized for RAG, tool use, and multilingual tasks. Latest version `command-r-plus-08-2024`. [22, 23]"
    },
    "costType": "userKeyRequired",
    "capabilities": ["text", "code", "json", "tool_use", "multilingual", "rag", "long_context", "reasoning"],
    "description": "Cohere's most performant model, specializing in agentic AI, tool use, complex RAG workflows, and multilingual applications. [22, 23]"
  },
  {
    "id": "command-r",
    "displayName": "Command R",
    "contextWindow": 128000,
    "cost": {
      "inputPerMillionTokens": 0.50,
      "outputPerMillionTokens": 1.50,
      "currency": "USD",
      "notes": "Optimized for conversational interaction, long context tasks, RAG and tool use. Latest version `command-r-08-2024`. [22, 23]"
    },
    "costType": "userKeyRequired",
    "capabilities": ["text", "code", "json", "tool_use", "multilingual", "rag", "long_context"],
    "description": "A scalable Cohere model balancing high performance with accuracy for production applications, strong in RAG, tool use, and 10 key languages. [22, 23]"
  },
  {
    "id": "jamba-large",
    "displayName": "Jamba Large 1.6",
    "contextWindow": 256000,
    "cost": {
      "inputPerMillionTokens": 2.00,
      "outputPerMillionTokens": 8.00,
      "currency": "USD",
      "notes": "Points to `jamba-large-1.6-2025-03`. Knowledge cutoff: March 5th, 2024. [24, 25]"
    },
    "costType": "userKeyRequired",
    "capabilities": ["text", "json", "tool_use", "multilingual", "long_context", "rag"],
    "description": "AI21's most powerful Jamba model with a 256K context window, built on a hybrid Mamba-Transformer architecture. Excels at long context tasks, RAG, and enterprise deployment. [25, 26, 27]"
  },
  {
    "id": "jamba-mini",
    "displayName": "Jamba Mini 1.6",
    "contextWindow": 256000,
    "cost": {
      "inputPerMillionTokens": 0.20,
      "outputPerMillionTokens": 0.40,
      "currency": "USD",
      "notes": "Points to `jamba-mini-1.6-2025-03`. Knowledge cutoff: March 5th, 2024. [24, 25]"
    },
    "costType": "userKeyRequired",
    "capabilities": ["text", "json", "tool_use", "multilingual", "long_context", "rag"],
    "description": "An efficient and lightweight Jamba model from AI21 with a 256K context window, offering a balance of performance and cost for a wide range of tasks. [24, 25, 26]"
  }
]
